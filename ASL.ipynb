{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PmbUim0Feb7",
        "outputId": "50498761-3c49-4a59-9a5c-4db6003f0b36"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txnevuRaNsne",
        "outputId": "d95fe898-9b4d-4c7b-d912-b564fc2c38e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "making dir\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "data_path = Path('data/')\n",
        "image_path = data_path/ 'asl_alphabet'\n",
        "\n",
        "if image_path.is_dir():\n",
        "  print('Folder already exists')\n",
        "else:\n",
        "  print('making dir')\n",
        "  image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "with open(data_path/'archive.zip', 'wb') as f:\n",
        "  request = requests.get('https://github.com/Loscano/ASL_alphabet/raw/refs/heads/main/archive.zip')\n",
        "  f.write(request.content)\n",
        "\n",
        "with zipfile.ZipFile(data_path/ 'archive.zip', 'r') as zip_ref:\n",
        "  zip_ref.extractall(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXylTRJPHQR-",
        "outputId": "3a96887b-c2f9-4ada-d38f-57b5faaea70a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading helper_functions.py\n"
          ]
        }
      ],
      "source": [
        "# Download helper functions from Learn PyTorch repo (if not already downloaded)\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"helper_functions.py already exists, skipping download\")\n",
        "else:\n",
        "  print(\"Downloading helper_functions.py\")\n",
        "  # Note: you need the \"raw\" GitHub URL for this to work\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "  with open(\"helper_functions.py\", \"wb\") as f:\n",
        "    f.write(request.content)\n",
        "\n",
        "# Import accuracy metric\n",
        "from helper_functions import accuracy_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LxpcPPtrBcf",
        "outputId": "a63aecc2-632f-4796-c72a-13e92b1e3f06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data/asl_alphabet/asl_alphabet_train/asl_alphabet_train, data/asl_alphabet/asl_alphabet_test/asl_alphabet_test\n"
          ]
        }
      ],
      "source": [
        "data_path = Path('data/')\n",
        "image_path = data_path/ 'asl_alphabet'\n",
        "train_path = image_path / 'asl_alphabet_train' / 'asl_alphabet_train'\n",
        "test_path = image_path / 'asl_alphabet_test' / 'asl_alphabet_test'\n",
        "print(f'{train_path}, {test_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rte9FMcR3oX8",
        "outputId": "30d9d08b-2d68-440e-a843-f087c16c97c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Root: data/asl_alphabet/asl_alphabet_test/asl_alphabet_test\n",
            "Dirs: []\n",
            "Files: ['U_test.jpg', 'V_test.jpg', 'B_test.jpg', 'N_test.jpg', 'Y_test.jpg', 'O_test.jpg', 'M_test.jpg', 'J_test.jpg', 'L_test.jpg', 'Z_test.jpg', 'G_test.jpg', 'K_test.jpg', 'H_test.jpg', 'X_test.jpg', 'nothing_test.jpg', 'T_test.jpg', 'D_test.jpg', 'S_test.jpg', 'E_test.jpg', 'F_test.jpg', 'C_test.jpg', 'A_test.jpg', 'W_test.jpg', 'Q_test.jpg', 'space_test.jpg', 'R_test.jpg', 'P_test.jpg', 'I_test.jpg']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "for root, dirs, files in os.walk(test_path):\n",
        "    print(f\"Root: {root}\")\n",
        "    print(f\"Dirs: {dirs}\")\n",
        "    print(f\"Files: {files}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1_N39Vyys0Py"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((255,255)),\n",
        "    transforms.RandomHorizontalFlip(p=.5),\n",
        "    transforms.ToTensor()\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ln7p6ENqvQcT"
      },
      "outputs": [],
      "source": [
        "from random import shuffle\n",
        "\n",
        "full_data = datasets.ImageFolder(\n",
        "    root = train_path,\n",
        "    transform=transform,\n",
        "    target_transform=None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IJscCXmPEzr9"
      },
      "outputs": [],
      "source": [
        "test_len = int(len(full_data)*.2)\n",
        "train_len = int(len(full_data) - test_len)\n",
        "\n",
        "train_set, test_set = torch.utils.data.random_split(full_data, [train_len, test_len])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nhM5t7vNuL2D"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_dataloader = DataLoader(\n",
        "    dataset=train_set,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=os.cpu_count()\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    dataset=test_set,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=os.cpu_count()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "y4KgvNXVANKF"
      },
      "outputs": [],
      "source": [
        "class model(torch.nn.Module):\n",
        "  def __init__(self, input_shape, hidden_units, output_shape):\n",
        "    super().__init__()\n",
        "    self.block_1 = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size=3, padding=1,stride=1),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, padding=1, stride=1),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.block_2 = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, padding=1,stride=1),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, padding=1, stride=1),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.classifier = torch.nn.Sequential(\n",
        "        torch.nn.Flatten(),\n",
        "        torch.nn.Linear(in_features=hidden_units*63*63,out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.block_1(x)\n",
        "    x = self.block_2(x)\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "\n",
        "asl_model = model(input_shape=3, hidden_units=10, output_shape=29)\n",
        "asl_model = asl_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fa2zm9y4IbOV"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize([255,255]),\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QeYCbju-Igty"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "\n",
        "def read_file_as_image(data):\n",
        "    if isinstance(data, (bytes, BytesIO)):\n",
        "      image = Image.open(BytesIO(data))\n",
        "    # If the input is a file path\n",
        "    elif isinstance(data, str):\n",
        "        image = Image.open(data)\n",
        "    else:\n",
        "        raise ValueError(\"Input must be a byte stream or a valid file path.\")\n",
        "\n",
        "    imageAsTensor = transform(image)\n",
        "    imageAsTensor = imageAsTensor.unsqueeze(dim=0)  # Add batch dimension\n",
        "    return imageAsTensor\n",
        "\n",
        "\n",
        "\n",
        "def predict(image_data):\n",
        "\n",
        "    input_tensor = read_file_as_image(image_data)\n",
        "    input_tensor = input_tensor.to(device)  # Move to the correct device\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        output = modelASL(input_tensor)  # Forward pass through the model\n",
        "\n",
        "    # Apply softmax to get probabilities\n",
        "    probabilities = torch.nn.functional.softmax(output, dim=1)\n",
        "\n",
        "    # Get the predicted class\n",
        "    predicted_class = torch.argmax(output, dim=1)\n",
        "\n",
        "    # Move the tensors to the CPU and convert to NumPy arrays\n",
        "    probabilities = probabilities.cpu().detach().numpy()\n",
        "    predicted_class = predicted_class.cpu().detach().numpy()\n",
        "\n",
        "    # Normalize probabilities (rounding for better readability)\n",
        "    probabilities = np.round(probabilities, 4)  # Round the probabilities here\n",
        "\n",
        "    # Convert to lists for easier use\n",
        "    probabilities_list = probabilities.tolist()\n",
        "    predicted_class_list = predicted_class.tolist()\n",
        "\n",
        "    return predicted_class_list, probabilities_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hPytECeyASHD"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=asl_model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1sfxSvFFAXkV"
      },
      "outputs": [],
      "source": [
        "def train_step(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer):\n",
        "  model.train()\n",
        "  train_loss, train_acc = 0,0\n",
        "  for batch, (X,y) in enumerate(data_loader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    model = model.to(device)\n",
        "\n",
        "    y_pred = model(X)\n",
        "\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss\n",
        "    train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  train_loss /= len(data_loader)\n",
        "  train_acc /= len(data_loader)\n",
        "  print(f'Train loss: {train_loss}, Train acc: {train_acc}')\n",
        "  return train_loss, train_acc\n",
        "\n",
        "def test_step(model: torch.nn.Module,\n",
        "              data_loader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module):\n",
        "  model.eval()\n",
        "\n",
        "  test_loss, test_acc = 0,0\n",
        "  with torch.inference_mode():\n",
        "    for batch, (X,y) in enumerate(data_loader):\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      model = model.to(device)\n",
        "\n",
        "      y_pred = model(X)\n",
        "\n",
        "      loss = loss_fn(y_pred, y)\n",
        "      test_loss += loss\n",
        "      test_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
        "\n",
        "    test_loss /= len(data_loader)\n",
        "    test_acc /= len(data_loader)\n",
        "    print(f'Test loss: {test_loss}, Test acc: {test_acc}')\n",
        "    return test_loss, test_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "CfSHjTeJAe9h"
      },
      "outputs": [],
      "source": [
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module = torch.nn.CrossEntropyLoss(),\n",
        "          epochs: int = 5):\n",
        "    # 2. Create empty results dictionary\n",
        "    results = {\"train_loss\": [],\n",
        "        \"train_acc\": [],\n",
        "        \"test_loss\": [],\n",
        "        \"test_acc\": []\n",
        "    }\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_acc = train_step(model=model,\n",
        "                                           data_loader= train_dataloader,\n",
        "                                           loss_fn=loss_fn,\n",
        "                                           optimizer=optimizer)\n",
        "        test_loss, test_acc = test_step(model=model,\n",
        "                                        data_loader=test_dataloader,\n",
        "                                        loss_fn=loss_fn)\n",
        "        results[\"train_loss\"].append(train_loss.item() if isinstance(train_loss, torch.Tensor) else train_loss)\n",
        "        results[\"train_acc\"].append(train_acc.item() if isinstance(train_acc, torch.Tensor) else train_acc)\n",
        "        results[\"test_loss\"].append(test_loss.item() if isinstance(test_loss, torch.Tensor) else test_loss)\n",
        "        results[\"test_acc\"].append(test_acc.item() if isinstance(test_acc, torch.Tensor) else test_acc)\n",
        "\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245,
          "referenced_widgets": [
            "bedf4c580d1645aba4bf8c20a0f81986",
            "df642359f15546ff9c54a7aba5430f6f",
            "43bc2fa020fc483c81238c9a4fe62aeb",
            "256a9b9c6c874a42a27747a2e582a507",
            "264a4af5e6be4afba798dcd7fdea802c",
            "c2f3eaf24ea44de68ca76c47b3e2de0b",
            "be7afde68d11442aa9dacf0572f4aa8c",
            "a8b67cb3920849b1a53a9922be31964c",
            "ec888591ebfd4c1ebb0a93b8e6628329",
            "e316542bf2ef4ac9ab19dcd6556d1506",
            "71e33d903f754dbfa6fa37547a2b0e1f"
          ]
        },
        "id": "482AEpdRAhkb",
        "outputId": "8f9ec73e-64e9-4a81-8d56-356ad4eaa701"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bedf4c580d1645aba4bf8c20a0f81986",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 1.3592159748077393, Train acc: 58.57902298850575\n",
            "Test loss: 0.4751603901386261, Test acc: 83.92501531862746\n",
            "Train loss: 0.30888399481773376, Train acc: 89.84626436781609\n",
            "Test loss: 0.29589512944221497, Test acc: 89.86098345588235\n",
            "Train loss: 0.17757301032543182, Train acc: 94.16091954022988\n",
            "Test loss: 0.3368496596813202, Test acc: 89.36504289215686\n",
            "Train loss: 0.12820425629615784, Train acc: 95.78448275862068\n",
            "Test loss: 0.24202346801757812, Test acc: 92.29090073529412\n",
            "Train loss: 0.09717188030481339, Train acc: 96.8146551724138\n",
            "Test loss: 0.1601981669664383, Test acc: 94.5101868872549\n",
            "Total training time: 1230.765 seconds\n"
          ]
        }
      ],
      "source": [
        "from timeit import default_timer as timer\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "torch.manual_seed(42)\n",
        "epoch = 5\n",
        "\n",
        "start_time = timer()\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "# Train model_0\n",
        "model_0_results = train(model=asl_model,\n",
        "                        train_dataloader=train_dataloader,\n",
        "                        test_dataloader=test_dataloader,\n",
        "                        optimizer=optimizer,\n",
        "                        loss_fn=loss_fn,\n",
        "                        epochs=NUM_EPOCHS)\n",
        "\n",
        "# End the timer and print out how long it took\n",
        "end_time = timer()\n",
        "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uDYBRAgArN6",
        "outputId": "ea62d5db-b635-4726-f3ef-22819005f8b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved successfully.\n"
          ]
        }
      ],
      "source": [
        "torch.save(asl_model.state_dict(), \"model.pth\")\n",
        "print(\"Model saved successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6l7qv9DBPKU4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "256a9b9c6c874a42a27747a2e582a507": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e316542bf2ef4ac9ab19dcd6556d1506",
            "placeholder": "​",
            "style": "IPY_MODEL_71e33d903f754dbfa6fa37547a2b0e1f",
            "value": " 5/5 [20:30&lt;00:00, 246.27s/it]"
          }
        },
        "264a4af5e6be4afba798dcd7fdea802c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43bc2fa020fc483c81238c9a4fe62aeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8b67cb3920849b1a53a9922be31964c",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec888591ebfd4c1ebb0a93b8e6628329",
            "value": 5
          }
        },
        "71e33d903f754dbfa6fa37547a2b0e1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8b67cb3920849b1a53a9922be31964c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be7afde68d11442aa9dacf0572f4aa8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bedf4c580d1645aba4bf8c20a0f81986": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df642359f15546ff9c54a7aba5430f6f",
              "IPY_MODEL_43bc2fa020fc483c81238c9a4fe62aeb",
              "IPY_MODEL_256a9b9c6c874a42a27747a2e582a507"
            ],
            "layout": "IPY_MODEL_264a4af5e6be4afba798dcd7fdea802c"
          }
        },
        "c2f3eaf24ea44de68ca76c47b3e2de0b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df642359f15546ff9c54a7aba5430f6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2f3eaf24ea44de68ca76c47b3e2de0b",
            "placeholder": "​",
            "style": "IPY_MODEL_be7afde68d11442aa9dacf0572f4aa8c",
            "value": "100%"
          }
        },
        "e316542bf2ef4ac9ab19dcd6556d1506": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec888591ebfd4c1ebb0a93b8e6628329": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
